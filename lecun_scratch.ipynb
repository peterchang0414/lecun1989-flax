{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lecun_scratch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peterchang0414/lecun1989-flax/blob/main/lecun_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oe2o-uZZd4yT",
        "outputId": "e2bfe962-6b7c-4c5b-9ee7-1d788fd58fb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |█▉                              | 10 kB 17.1 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 20 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 30 kB 25.7 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 40 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 51 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 61 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 71 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 81 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 92 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 102 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 112 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 122 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 133 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 143 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 153 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 163 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 174 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184 kB 8.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 136 kB 46.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 70 kB 6.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q flax"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "\n",
        "from flax import linen as nn\n",
        "from torchvision import datasets\n",
        "\n",
        "data = datasets.MNIST('./data', train=True, download=True)\n",
        "\n",
        "# Adapted from https://github.com/karpathy/lecun1989-repro/blob/master/prepro.py\n",
        "def get_datasets():\n",
        "  train_test = {}\n",
        "  for split in {'train', 'test'}:\n",
        "    data = datasets.MNIST('./data', train=split=='train', download=True)\n",
        "    \n",
        "    n = 1000 if split == 'train' else 1\n",
        "    key = jax.random.PRNGKey(0)\n",
        "    rp = jax.random.permutation(key, len(data))[:n]\n",
        "\n",
        "    X = jnp.full((n, 16, 16, 1), 0.0, dtype=jnp.float32)\n",
        "    Y = jnp.full((n, 10), -1.0, dtype=jnp.float32)\n",
        "    for i, ix in enumerate(rp):\n",
        "      I, yint = data[int(ix)]\n",
        "      xi = jnp.array(I, dtype=np.float32) / 127.5 - 1.0\n",
        "      xi = jax.image.resize(xi, (16, 16), 'bilinear')\n",
        "      X = X.at[i].set(np.expand_dims(xi, axis=2))\n",
        "      Y = Y.at[i, yint].set(1.0)\n",
        "    train_test[split] = (X, Y)\n",
        "  return train_test"
      ],
      "metadata": {
        "id": "pc7McMNRnt2E"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flax import linen as nn\n",
        "from flax.training import train_state\n",
        "from flax.linen.activation import tanh\n",
        "import optax\n",
        "from typing import Callable\n",
        "\n",
        "class Net(nn.Module):\n",
        "  bias_init: Callable = nn.initializers.zeros\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    # H1 layer\n",
        "    # For weight initialization, Karpathy used numerator of 2.4 \n",
        "    # which is very close to sqrt(6) used by he_uniform\n",
        "    # By default, weight-sharing forces bias-sharing and therefore\n",
        "    # we add the bias separately.\n",
        "    bias1 = self.param('bias1', self.bias_init, (8, 8, 12))\n",
        "    bias2 = self.param('bias2', self.bias_init, (4, 4, 12))\n",
        "    bias3 = self.param('bias3', self.bias_init, (30,))\n",
        "    bias4 = self.param('bias4', nn.initializers.constant(-1.0), (10,))\n",
        "    print(\"1: \", x.shape)\n",
        "    x = jnp.pad(x, [(0,0),(2,2),(2,2),(0,0)], constant_values=-1.0)\n",
        "    print(\"2: \", x.shape)\n",
        "    x = nn.Conv(features=12, kernel_size=(5,5), strides=2, padding='VALID',\n",
        "                use_bias=False, kernel_init=nn.initializers.he_uniform())(x)\n",
        "    print(\"3: \", x.shape)\n",
        "    x = tanh(x + bias1)\n",
        "    print(\"4: \", x.shape)\n",
        "    # slice1 = nn.Conv(features=8, kernel_size=(5,5), strides=2, padding=-1.0,\n",
        "    #                 use_bias=False, kernel_init=nn.initializers.he_uniform())(x[..., 0:8])\n",
        "    # slice1 = nn.Conv(features=8, kernel_size=(5,5), strides=2, padding=-1.0,\n",
        "    #                 use_bias=False, kernel_init=nn.initializers.he_uniform())(x[..., 0:8])\n",
        "    x = jnp.pad(x, [(0,0),(2,2),(2,2),(0,0)], constant_values=-1.0)\n",
        "    print(\"5: \", x.shape)\n",
        "    x = nn.Conv(features=12, kernel_size=(5,5), strides=2, padding='VALID',\n",
        "                use_bias=False, kernel_init=nn.initializers.he_uniform())(x)\n",
        "    print(\"6: \", x.shape)\n",
        "    x = tanh(x + bias2)\n",
        "    print(\"7: \", x.shape)\n",
        "    x = x.reshape((x.shape[0], -1))\n",
        "    x = nn.Dense(features=30, use_bias=False)(x)\n",
        "    x = tanh(x + bias3)\n",
        "    print(\"8: \", x.shape)\n",
        "    x = nn.Dense(features=10, use_bias=False)(x)\n",
        "    x = tanh(x + bias4)\n",
        "    print(\"9: \", x.shape)\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "hk3obOlvqoDZ"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_step(params, X, Y):\n",
        "  Yhat = Net().apply({'params': params}, X)\n",
        "  print(type(Y))\n",
        "  print(\"yhat.argmax() = \", jnp.argmax(Yhat, -1))\n",
        "  loss = jnp.mean((Yhat - Y)**2)\n",
        "  err = jnp.mean(jnp.argmax(Y, -1) != jnp.argmax(Yhat, -1)).astype(float)\n",
        "  return loss, err"
      ],
      "metadata": {
        "id": "KUCi-jvDXuha"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_split(data, split, params):\n",
        "  X, Y = data[split]\n",
        "  loss, err = eval_step(params, X, Y)\n",
        "  print(f\"eval: split {split:5s}. loss {loss:e}. error {err*100:.2f}%. misses: {int(err*Y.shape[0])}\")"
      ],
      "metadata": {
        "id": "D9KDZtpgVUBu"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def train_step(state, imgs, labels):\n",
        "  def loss_fn(params):\n",
        "    result = Net().apply({'params': params}, imgs)\n",
        "    loss = jnp.mean((result - labels)**2)\n",
        "    return loss, result\n",
        "  \n",
        "  (_, result), grads = jax.value_and_grad(loss_fn, has_aux=True)(state.params)\n",
        "  state = state.apply_gradients(grads=grads)\n",
        "  metrics = compute_metrics()"
      ],
      "metadata": {
        "id": "JMAOd3CuSelP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_test = get_datasets()"
      ],
      "metadata": {
        "id": "m-TvWWooE8Th"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train_test['train'][0]"
      ],
      "metadata": {
        "id": "_RXV0OQ0E_Ta"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qi9Ul0yIFE2y",
        "outputId": "3217ceed-7697-4565-d013-9758ce4956e9"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 16, 16, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "key = jax.random.PRNGKey(0)\n",
        "cnn = Net()\n",
        "param = cnn.init(key, train)['params']"
      ],
      "metadata": {
        "id": "ei-31RL7D00w",
        "outputId": "7e590972-64f6-4d4f-9bc3-8363797fae4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:  (1000, 16, 16, 1)\n",
            "2:  (1000, 20, 20, 1)\n",
            "3:  (1000, 8, 8, 12)\n",
            "4:  (1000, 8, 8, 12)\n",
            "5:  (1000, 12, 12, 12)\n",
            "6:  (1000, 4, 4, 12)\n",
            "7:  (1000, 4, 4, 12)\n",
            "8:  (1000, 30)\n",
            "9:  (1000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(jax.tree_map(lambda x: x.shape, param))"
      ],
      "metadata": {
        "id": "7NraePjQZLEO",
        "outputId": "883ffeee-bdd0-4521-851c-cb112f991e6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FrozenDict({\n",
            "    Conv_0: {\n",
            "        kernel: (5, 5, 1, 12),\n",
            "    },\n",
            "    Conv_1: {\n",
            "        kernel: (5, 5, 12, 12),\n",
            "    },\n",
            "    Dense_0: {\n",
            "        kernel: (192, 30),\n",
            "    },\n",
            "    Dense_1: {\n",
            "        kernel: (30, 10),\n",
            "    },\n",
            "    bias1: (8, 8, 12),\n",
            "    bias2: (4, 4, 12),\n",
            "    bias3: (30,),\n",
            "    bias4: (10,),\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_split(train_test, 'train', param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnEGr2MhPQf0",
        "outputId": "96ffe785-f8a9-40bc-c9f8-481e8c3dc6bf"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:  (1000, 16, 16, 1)\n",
            "2:  (1000, 20, 20, 1)\n",
            "3:  (1000, 8, 8, 12)\n",
            "4:  (1000, 8, 8, 12)\n",
            "5:  (1000, 12, 12, 12)\n",
            "6:  (1000, 4, 4, 12)\n",
            "7:  (1000, 4, 4, 12)\n",
            "8:  (1000, 30)\n",
            "9:  (1000, 10)\n",
            "<class 'jaxlib.xla_extension.DeviceArray'>\n",
            "yhat.argmax() =  [6 7 3 3 6 7 3 3 3 7 7 3 6 3 3 3 3 6 3 6 6 6 3 6 3 3 3 6 3 3 3 6 6 6 3 3 3\n",
            " 3 3 3 6 6 3 3 3 6 6 3 3 3 3 3 3 3 6 3 6 6 3 6 3 3 6 3 3 3 6 3 7 3 3 3 6 3\n",
            " 3 3 3 3 3 3 3 7 6 3 3 6 6 3 3 3 6 3 6 6 3 6 3 6 3 3 3 3 6 3 6 3 6 3 3 3 6\n",
            " 3 6 6 6 3 6 6 3 3 4 3 3 6 3 6 3 6 3 6 3 3 3 3 6 6 6 3 6 6 3 6 3 3 7 3 6 3\n",
            " 3 3 3 6 3 3 3 6 6 6 3 6 6 6 6 3 6 3 6 6 3 6 3 3 6 6 7 6 3 3 3 6 6 6 4 6 6\n",
            " 4 3 3 3 3 6 3 6 3 3 6 3 4 6 6 3 6 3 6 6 3 4 6 3 6 6 6 3 6 3 3 3 3 6 3 6 6\n",
            " 3 6 7 6 3 6 3 3 3 6 7 6 3 6 3 6 6 3 6 6 3 6 3 6 6 3 6 6 6 3 6 3 6 3 3 6 7\n",
            " 3 3 3 3 6 3 3 6 6 3 3 3 3 3 3 3 6 3 6 6 6 6 3 3 3 6 3 7 6 7 6 7 6 3 3 7 3\n",
            " 6 6 3 3 3 3 6 6 3 3 3 6 3 6 3 3 3 3 6 3 6 3 3 6 6 6 6 6 4 3 3 3 3 6 3 3 3\n",
            " 3 3 6 7 3 6 6 6 6 3 6 6 6 6 6 7 3 6 6 3 6 6 3 6 3 3 3 6 6 6 6 6 6 3 6 7 3\n",
            " 3 6 6 3 3 3 3 6 6 7 3 3 6 3 3 6 6 7 3 3 6 6 3 3 6 3 3 6 7 3 3 3 6 3 3 3 7\n",
            " 6 3 6 3 3 3 6 6 6 3 6 6 3 3 3 3 3 6 3 3 3 3 4 6 3 6 6 3 4 3 6 6 3 3 3 6 7\n",
            " 6 3 3 3 3 6 6 7 3 3 3 6 6 6 7 3 6 3 3 3 3 3 6 3 6 3 3 6 3 6 3 6 3 3 3 3 3\n",
            " 3 6 7 3 3 6 3 3 6 7 3 3 6 3 6 3 3 3 3 3 3 6 7 6 6 3 3 3 3 3 3 3 3 3 4 3 3\n",
            " 3 6 3 6 3 3 3 3 6 3 3 4 7 6 3 7 6 3 3 3 3 6 6 3 3 3 3 3 6 3 6 3 3 4 3 3 3\n",
            " 6 3 6 6 6 3 3 3 6 3 3 3 3 3 3 6 6 3 3 6 6 3 3 3 3 3 3 3 3 3 6 3 3 3 3 4 6\n",
            " 3 3 3 3 6 6 6 6 4 6 6 6 6 3 6 7 3 6 6 6 3 6 7 3 6 3 3 6 4 6 3 3 3 6 7 6 6\n",
            " 3 3 3 7 3 6 4 6 3 6 3 3 3 6 3 6 3 7 3 3 6 3 3 3 3 3 6 6 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 7 3 6 3 6 3 3 6 6 3 6 7 3 3 3 3 3 3 3 3 3 3 3 3 6 3 6 3 3 6 3 6\n",
            " 3 3 3 6 6 3 6 3 3 6 3 3 6 6 3 3 3 3 3 3 6 6 6 6 3 6 3 3 3 3 7 6 6 3 6 3 3\n",
            " 3 3 3 3 3 6 3 6 3 6 6 3 3 3 6 6 3 3 3 6 6 6 6 3 3 6 3 6 6 6 3 6 3 3 3 3 3\n",
            " 3 6 4 3 6 3 6 3 6 6 6 6 3 6 4 3 3 3 6 3 3 6 6 3 6 3 3 6 6 4 3 7 6 3 4 3 3\n",
            " 3 6 3 3 3 3 3 6 3 3 3 3 3 6 3 3 6 3 3 6 6 6 6 6 6 7 6 6 6 3 3 6 6 3 6 3 7\n",
            " 6 7 6 3 3 6 6 7 6 3 6 7 6 3 6 3 3 6 3 6 3 6 3 6 3 3 6 4 6 3 3 6 3 3 6 7 3\n",
            " 6 3 6 3 6 3 3 6 6 6 3 6 3 3 6 3 3 3 3 6 3 3 3 3 6 6 6 3 6 3 3 3 3 3 3 6 6\n",
            " 6 3 3 3 3 3 3 4 3 3 6 4 3 3 3 3 3 3 3 3 6 6 6 6 3 3 3 3 3 6 6 3 3 3 3 6 3\n",
            " 3 6 3 3 7 3 3 6 3 6 6 6 3 6 7 6 6 3 3 6 6 6 3 3 3 3 3 6 6 3 3 6 3 6 3 3 3\n",
            " 3]\n",
            "eval: split train. loss 4.543942e-01. error 87.60%. misses: 876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DD-mdHpEXRUl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}